# -*- coding: utf-8 -*-
"""ipmlab(CSI) 모델링.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1to4_6wMDhHZa-Sf7b5Cej1Sp6macKBQA
"""

from sklearn.model_selection import train_test_split
from sklearn import metrics
from imblearn.over_sampling import RandomOverSampler
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier

"""# 모델 생성(Decision tree)"""

# 특성과 레이블 추출

X = []
y = []

for key, value in labeling_result.items():
    X.append([value['공공민간구분_num'], value['날씨_num'],value['온도'], value['습도'],value['시설물대분류_num'], value['공종(대분류)_num'],value['공종(소분류)_num'], value['시도구분_num'],value['안전관리계획_num']
              , value['공사비_num'], value['공정율_num'],value['작업자수_num'], value['프로세스_num'] , value['설계안정성검토_num'], value['사고월_num'], value['사고요일_num'], value['사고시간_num']])
    y.append(value['사고객체(대분류)_num'])

X, y = RandomOverSampler(random_state=0).fit_resample(X, y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 의사결정 트리 모델 생성 및 훈련
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = metrics.accuracy_score(y_test, y_pred)
f1_score = metrics.f1_score(y_test, y_pred, average='macro')

print("Accuracy:", accuracy)
print("F1 Score:", f1_score)

X, y = RandomOverSampler(random_state=0).fit_resample(X, y)

#훈련 세트와 테스트 세트 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 의사결정 트리 분류 모델 생성
base_model = DecisionTreeClassifier()

# 배깅(Bagging) 모델 생성
model = BaggingClassifier(base_estimator=base_model, n_estimators=10, random_state=42)

# 훈련 데이터에 배깅 모델 훈련
model.fit(X_train, y_train)

# 테스트 데이터 예측
y_pred = model.predict(X_test)

# 평가 메트릭 계산
accuracy = metrics.accuracy_score(y_test, y_pred)
f1_score = metrics.f1_score(y_test, y_pred, average='macro')

print("Accuracy:", accuracy)
print("F1 Score:", f1_score)

"""# 모델 생성(XGBoost)"""

X = []
y = []

for key, value in labeling_result.items():
    X.append([value['공공민간구분_num'], value['날씨_num'],value['온도'], value['습도'],value['시설물대분류_num'], value['공종(대분류)_num'],value['공종(소분류)_num'], value['시도구분_num'],value['안전관리계획_num']
              , value['공사비_num'], value['공정율_num'],value['작업자수_num'], value['프로세스_num'] , value['설계안정성검토_num'], value['사고월_num'], value['사고요일_num'], value['사고시간_num']])
    y.append(value['사고객체(대분류)_num'])

X, y = RandomOverSampler(random_state=0).fit_resample(X, y)

#ovesampling =>RandomOverSampler 사용

# 훈련 세트와 테스트 세트 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# XGBoost 오류로 이과정을 진행 해야 함
le = LabelEncoder()
y_train = le.fit_transform(y_train)

# XGBoost 분류 모델 생성(서울대에서 제시한 하이퍼파라미터 적용)
model = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=7, objective = 'multi:softprob', eval_metric = 'mlogloss', colsample_bytree=0.75, min_child_weight=1)

# 훈련 데이터에 XGBoost 모델 훈련
model.fit(X_train, y_train)

# 테스트 데이터 예측
y_pred = model.predict(X_test)

# 예측 결과 디코딩하여 원래의 클래스 값으로 변환
y_pred = le.inverse_transform(y_pred)

# 평가 메트릭 계산
accuracy = metrics.accuracy_score(y_test, y_pred)
f1_score = metrics.f1_score(y_test, y_pred, average='macro')

print("Accuracy:", accuracy)
print("F1 Score:", f1_score)

"""# 하이퍼 파라미터 계산"""

X = df.drop(['사고상태', '사고일시','인적사고종류(대분류)','사고객체(대분류)','사고객체(소분류)','사망자','부상자','사망_부상여부'], axis=1)
y = df['사고객체(대분류)']

#ovesampling =>RandomOverSampler 사용
X, y = RandomOverSampler(random_state=0).fit_resample(X, y)

# 훈련 세트와 테스트 세트 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# XGBoost 분류 모델 생성
model = XGBClassifier(random_state=42)

# 하이퍼파라미터 그리드 준비
param_grid = {
    'learning_rate': [0.1, 0.01],
    'max_depth': [3, 5, 7],
    'n_estimators': [100, 200, 300],
    'min_child_weight': [1, 3, 5],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

# GridSearchCV를 사용하여 최적의 하이퍼파라미터 탐색
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# 최적의 하이퍼파라미터와 그 때의 성능 출력
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)

# 최적의 하이퍼파라미터로 모델 재훈련
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

# 테스트 데이터 예측
y_pred = best_model.predict(X_test)

# 평가 메트릭 계산
accuracy = metrics.accuracy_score(y_test, y_pred)
f1_score = metrics.f1_score(y_test, y_pred, average='macro')

print("Accuracy:", accuracy)
print("F1 Score:", f1_score)